{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 1,
     "source": [
      "Exploring Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook was authored by John Vivian (jtvivian@gmail.com)\n",
      "\n",
      "    1. Plot the accuracy of the Label by the BARCODE (by CHUNK score) \n",
      "    2. Plot Accuracy of context by the BARCODE \n",
      "    3. Plot soft-call accuracy \n",
      "    4. Try only states 8,9,10 in accuracy \n",
      "    5. Compare reread accuracy from rereads to single reads"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Accuracy Plot of Label given the Barcode "
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "failed to import Cython: cannot import name PyrexScanner\n"
       ]
      },
      {
       "ename": "ImportError",
       "evalue": "Building module PyPore.cparsers failed: ['DistutilsPlatformError: Cython does not appear to be installed\\n']",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-268f2e9ce336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'../Models'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mSimple_Model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Acquire Events\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\John\\Dropbox\\Work\\New Nanopore Work (6-20-2014)\\Helicase Reread Project HMM\\Helicase-Reread-Project\\Models\\Simple_Model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0myahmm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPyPore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataTypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\PyPore\\DataTypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mparsers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0malignment\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\PyPore\\parsers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyximport\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mpyximport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msetup_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'include_dirs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_include\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPyPore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcparsers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFastStatSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyximport\\pyximport.pyc\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyxbuild_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                  \u001b[0mbuild_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m                                  language_level=self.language_level)\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyximport\\pyximport.pyc\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, pyxfilename, pyxbuild_dir, is_package, build_inplace, language_level, so_path)\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mmodule_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             so_path = build_module(module_name, pyxfilename, pyxbuild_dir,\n\u001b[1;32m--> 209\u001b[1;33m                                    inplace=build_inplace, language_level=language_level)\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mso_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_package\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__path__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyximport\\pyximport.pyc\u001b[0m in \u001b[0;36mbuild_module\u001b[1;34m(name, pyxfilename, pyxbuild_dir, inplace, language_level)\u001b[0m\n\u001b[0;32m    184\u001b[0m                                   \u001b[0msetup_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                                   reload_support=pyxargs.reload_support)\n\u001b[0m\u001b[0;32m    187\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mso_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot find: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mso_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pyximport\\pyxbuild.pyc\u001b[0m in \u001b[0;36mpyx_to_dll\u001b[1;34m(filename, ext, force_rebuild, build_in_temp, pyxbuild_dir, setup_args, reload_support, inplace)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mobj_build_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m# Python distutils get_outputs()[ returns a wrong so_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[1;31m# when --inplace ; see http://bugs.python.org/issue5977\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;31m# workaround:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             so_path = os.path.join(os.path.dirname(filename),\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\distutils\\dist.pyc\u001b[0m in \u001b[0;36mrun_commands\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    951\u001b[0m         \"\"\"\n\u001b[0;32m    952\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommands\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[1;31m# -- Methods that operate on its Commands --------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\distutils\\dist.pyc\u001b[0m in \u001b[0;36mrun_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0mcmd_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_command_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[0mcmd_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_finalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m         \u001b[0mcmd_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhave_run\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\Cython\\Distutils\\build_ext.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0moptimization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0m_build_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_extensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\distutils\\command\\build_ext.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;31m# Now actually compile and link everything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_extensions_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\Cython\\Distutils\\build_ext.pyc\u001b[0m in \u001b[0;36mbuild_extensions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msources\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcython_sources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\Cython\\Distutils\\build_ext.pyc\u001b[0m in \u001b[0;36mcython_sources\u001b[1;34m(self, sources, extension)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"failed to import Cython: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mDistutilsPlatformError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cython does not appear to be installed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mnew_sources\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: Building module PyPore.cparsers failed: ['DistutilsPlatformError: Cython does not appear to be installed\\n']"
       ]
      }
     ],
     "input": [
      "%matplotlib inline\n",
      "from IPython.display import display, clear_output\n",
      "import sys, os, random, argparse\n",
      "import numpy as np\n",
      "import Methods\n",
      "import seaborn as sns\n",
      "\n",
      "sys.path.append( '../Models' )\n",
      "from Simple_Model import *\n",
      "\n",
      "# Acquire Events\n",
      "source = '../Data/JSON/Final_Train/'\n",
      "for root, dirnames, filenames in os.walk(source):\n",
      "    events = filenames\n",
      "    \n",
      "# Randomize List\n",
      "random.shuffle( events )\n",
      "\n",
      "# Break into 5 equal groups\n",
      "event_groups = [ events[i::5] for i in xrange(5) ]\n",
      "    \n",
      "## 2. For every group: withold and train on other 4. \n",
      "# Create array\n",
      "data = np.zeros( (10, 12) ) \n",
      "\n",
      "## 3. Read in Untrained HMM then train\n",
      "with open ( '../Data/HMMs/Temp_Test.txt', 'r' ) as file:\n",
      "    model = Model.read( file ) \n",
      "#print '\\nTraining HMM: Witholding group {}. Training size {}. Cscore: {}'.format( i+1, len(training), cscore )\n",
      "#model.train( sequences )\n",
      "\n",
      "# Acquire indices\n",
      "indices = { state.name: i for i, state in enumerate( model.states ) }\n",
      "\n",
      "## In order to speed this thing up, assign events to lists by cscore so that\n",
      "## it doesn't need to be done every iteration.\n",
      "ranked_events = {}\n",
      "for i in xrange(10):\n",
      "    ranked_events[i] = []\n",
      "\n",
      "print 'Ranking Events by CHUNK Score'\n",
      "counter = 0\n",
      "for event_name in events:  \n",
      "    counter+=1\n",
      "    # Convert JSON to event\n",
      "    event = Event.from_json( source + event_name )\n",
      "\n",
      "    # Convert event into a list of means\n",
      "    means = [seg['mean'] for seg in event.segments]\n",
      "\n",
      "    # Perform forward_backward algorithm\n",
      "    trans, ems = model.forward_backward( means )\n",
      "\n",
      "    # Partition the event into 'chunks' of context / label regions\n",
      "    contexts, labels = partition_event( indices, event, ems, means)\n",
      "\n",
      "    # Get chunk scores\n",
      "    contexts, labels = chunk_score( indices, contexts, labels, ems )\n",
      "\n",
      "    # Get chunk vector\n",
      "    contexts, labels = chunk_vector( indices, contexts, labels, ems )\n",
      "    if contexts and labels:\n",
      "        max_c = max( [ x[0] for x in contexts ] ) \n",
      "        max_l = max( [ x[0] for x in labels ] )\n",
      "\n",
      "        for i in xrange(9,-1,-1):\n",
      "            if max_c >= i*.10 and max_l >= i*.10:\n",
      "                print 'C:{}\\tL:{}\\tAssigned:{}\\tPercentage:{}%\\r'.format(round(max_c,2), round(max_l,2), i, round((counter*1.0/len(events))*100,2)),\n",
      "                ranked_events[i].append( (event_name, contexts, labels, ems, means) )\n",
      "                break\n",
      "print '\\n'\n",
      "for i in ranked_events:\n",
      "    print i, len(ranked_events[i])\n",
      "\n",
      "## Iterate through the range of cutoff values: \n",
      "cscores = [ 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0 ]\n",
      "data_counter = 0\n",
      "for cscore in cscores:\n",
      "    ## Keep track of hard calls -- list with 'n' and 'correct'\n",
      "    hard_calls = { 'C': [0, 0], 'mC' : [0,0], 'hmC' : [0,0] }\n",
      "\n",
      "    counters = []\n",
      "    #for i in xrange(1): # 5 for real k-fold\n",
      "    counter = 0\n",
      "\n",
      "    # Bins to hold counts\n",
      "    bins = { 'f': 0, 'l': 0, 'r':0, 'b': 0, 'i': 0, 'h': 0 }                # Counter for hard calls\n",
      "    soft_calls = { 'f': [], 'l': [], 'r':[], 'b': [], 'i': [], 'h': [] }    # Will hold soft calls\n",
      "    \n",
      "    ## For a given cscore, group and iterate through.\n",
      "    event_sum = 0\n",
      "    for i in xrange(9, int(cscore*10-1), -1):\n",
      "        event_sum += len(ranked_events[i])\n",
      "        for event in ranked_events[i]:\n",
      "            # Unpack Variables\n",
      "            event_name = event[0]\n",
      "            contexts = event[1]\n",
      "            labels = event[2]\n",
      "            ems = event[3]\n",
      "            means = event[4]\n",
      "            barcode = event_name.split('-')[0]\n",
      "            # update counter\n",
      "            counter += 1\n",
      "           \n",
      "            ## Single Read Methods\n",
      "            fchunk, fcall = Methods.first_chunk( contexts, labels, cscore )\n",
      "            lchunk, lcall = Methods.last_chunk( contexts, labels, cscore )\n",
      "            rchunk, rcall = Methods.random_chunk( contexts, labels, cscore )\n",
      "            \n",
      "            ## Multi-Read Methods\n",
      "            bchunk, bcall = Methods.best_chunk( contexts, labels )\n",
      "            ichunk, icall = Methods.ind_consensus( contexts, labels, cscore )\n",
      "            hchunk, hcall = Methods.hmm_consensus( indices, ems, len(means), chunk_vector )\n",
      "\n",
      "             # First Chunk\n",
      "            soft_calls['f'].append( fchunk )\n",
      "            if barcode == fcall[1]:\n",
      "                bins['f'] += 1\n",
      "                \n",
      "            # Last Chunk\n",
      "            soft_calls['l'].append( lchunk )\n",
      "            if barcode == lcall[1]:\n",
      "                bins['l'] += 1\n",
      "                \n",
      "            # Random Chunk\n",
      "            soft_calls['r'].append( rchunk )\n",
      "            if barcode == rcall[1]:\n",
      "                bins['r'] += 1\n",
      "            \n",
      "            # Best Chunk\n",
      "            soft_calls['b'].append( bchunk )\n",
      "            if barcode == bcall[1]:\n",
      "                bins['b'] += 1\n",
      "                \n",
      "            # Ind Consensus\n",
      "            soft_calls['i'].append( ichunk )\n",
      "            if barcode == icall[1]:\n",
      "                bins['i'] += 1\n",
      "                \n",
      "            #HMM Consensus\n",
      "            soft_calls['h'].append( hchunk )\n",
      "            if barcode == hcall[1]:\n",
      "                bins['h'] += 1\n",
      "                \n",
      "    j = data_counter\n",
      "    data[j][0] = bins['f']*1.0 / counter\n",
      "    data[j][1] = np.mean(soft_calls['f'])\n",
      "    data[j][2] = bins['l']*1.0 / counter\n",
      "    data[j][3] = np.mean(soft_calls['l'])\n",
      "    data[j][4] = bins['r']*1.0 / counter\n",
      "    data[j][5] = np.mean(soft_calls['r'])\n",
      "    data[j][6] = bins['h']*1.0 / counter\n",
      "    data[j][7] = np.mean(soft_calls['h'])\n",
      "    data[j][8] = bins['b']*1.0 / counter\n",
      "    data[j][9] = np.mean(soft_calls['b'])\n",
      "    data[j][10] = bins['i']*1.0 / counter\n",
      "    data[j][11] = np.mean(soft_calls['i'])\n",
      "    data_counter += 1"
     ],
     "language": "python",
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "accuracy_by_filter_score( data, 'Label Accuracy by Chunk Score' )"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Accuray of Context by Barcode"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "data_counter = 0\n",
      "for cscore in cscores:\n",
      "    #print '\\nCscore:{}\\n'.format(cscore)\n",
      "   \n",
      "    # Counters\n",
      "    counters = []\n",
      "    counter = 0\n",
      "    \n",
      "    # Bins to hold counts\n",
      "    bins = { 'f': 0, 'l': 0, 'r':0, 'b': 0, 'i': 0, 'h': 0 }                # Counter for hard calls\n",
      "    soft_calls = { 'f': [], 'l': [], 'r':[], 'b': [], 'i': [], 'h': [] }    # Will hold soft calls\n",
      "    \n",
      "    ## For a given cscore, group and iterate through.\n",
      "    event_sum = 0\n",
      "    for i in xrange(9, int(cscore*10-1), -1):\n",
      "        event_sum += len(ranked_events[i])\n",
      "        for event in ranked_events[i]:\n",
      "            \n",
      "            # Unpack Variables\n",
      "            event_name = event[0]\n",
      "            contexts = event[1]\n",
      "            labels = event[2]\n",
      "            ems = event[3]\n",
      "            means = event[4]\n",
      "            barcode = event_name.split('-')[0]\n",
      "            # update counter\n",
      "            counter += 1\n",
      "           \n",
      "            ## Single Read Methods\n",
      "            fchunk, fcall = Methods.first_chunk( contexts, labels, cscore )\n",
      "            lchunk, lcall = Methods.last_chunk( contexts, labels, cscore )\n",
      "            rchunk, rcall = Methods.random_chunk( contexts, labels, cscore )\n",
      "            \n",
      "            ## Multi-Read Methods\n",
      "            bchunk, bcall = Methods.best_chunk( contexts, labels )\n",
      "            ichunk, icall = Methods.ind_consensus( contexts, labels, cscore )\n",
      "            hchunk, hcall = Methods.hmm_consensus( indices, ems, len(means), chunk_vector )\n",
      "\n",
      "             # First Chunk\n",
      "            soft_calls['f'].append( fchunk )\n",
      "            if barcode == fcall[0]:\n",
      "                bins['f'] += 1\n",
      "                \n",
      "            # Last Chunk\n",
      "            soft_calls['l'].append( lchunk )\n",
      "            if barcode == lcall[0]:\n",
      "                bins['l'] += 1\n",
      "                \n",
      "            # Random Chunk\n",
      "            soft_calls['r'].append( rchunk )\n",
      "            if barcode == rcall[0]:\n",
      "                bins['r'] += 1\n",
      "            \n",
      "            # Best Chunk\n",
      "            soft_calls['b'].append( bchunk )\n",
      "            if barcode == bcall[0]:\n",
      "                bins['b'] += 1\n",
      "                \n",
      "            # Ind Consensus\n",
      "            soft_calls['i'].append( ichunk )\n",
      "            if barcode == icall[0]:\n",
      "                bins['i'] += 1\n",
      "            #print 'Context_hc: {}\\tBarcode: {}\\tEvent_Name:{}'.format( icall[0], barcode, event_name )\n",
      "                \n",
      "            #HMM Consensus\n",
      "            soft_calls['h'].append( hchunk )\n",
      "            if barcode == hcall[0]:\n",
      "                bins['h'] += 1\n",
      "                \n",
      "    j = data_counter\n",
      "    data[j][0] = bins['f']*1.0 / counter\n",
      "    data[j][1] = np.mean(soft_calls['f'])\n",
      "    data[j][2] = bins['l']*1.0 / counter\n",
      "    data[j][3] = np.mean(soft_calls['l'])\n",
      "    data[j][4] = bins['r']*1.0 / counter\n",
      "    data[j][5] = np.mean(soft_calls['r'])\n",
      "    data[j][6] = bins['h']*1.0 / counter\n",
      "    data[j][7] = np.mean(soft_calls['h'])\n",
      "    data[j][8] = bins['b']*1.0 / counter\n",
      "    data[j][9] = np.mean(soft_calls['b'])\n",
      "    data[j][10] = bins['i']*1.0 / counter\n",
      "    data[j][11] = np.mean(soft_calls['i'])\n",
      "    data_counter += 1"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "accuracy_by_filter_score( data, 'Accuracy of Context Chunk by Barcode -- Old \"Test HMM\"' )"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Plot Soft-Call Accuracy "
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "accuracy_by_filter_score( data, 'Soft-Call Accuracy of Context by Barcode', sc=True )"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Compare Reread Accuracy between Single Reads and Rereads"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "# Rank Events by CHUNK Score\n",
      "ranked_events = {}\n",
      "for i in xrange(10):\n",
      "    ranked_events[i] = []\n",
      "\n",
      "print 'Ranking Events by CHUNK Score'\n",
      "counter = 0\n",
      "for event_name in events:  \n",
      "    counter+=1\n",
      "    # Convert JSON to event\n",
      "    event = Event.from_json( source + event_name )\n",
      "\n",
      "    # Convert event into a list of means\n",
      "    means = [seg['mean'] for seg in event.segments]\n",
      "\n",
      "    # Perform forward_backward algorithm\n",
      "    trans, ems = model.forward_backward( means )\n",
      "\n",
      "    # Partition the event into 'chunks' of context / label regions\n",
      "    contexts, labels = partition_event( indices, event, ems, means)\n",
      "\n",
      "    # Get chunk scores\n",
      "    contexts, labels = chunk_score( indices, contexts, labels, ems )\n",
      "\n",
      "    # Get chunk vector\n",
      "    contexts, labels = chunk_vector( indices, contexts, labels, ems )\n",
      "    \n",
      "    if contexts and labels:\n",
      "        max_c = max( [ x[0] for x in contexts ] ) \n",
      "        max_l = max( [ x[0] for x in labels ] )\n",
      "        \n",
      "        for i in xrange(9,-1,-1):\n",
      "            if max_c >= i*.10 and max_l >= i*.10:\n",
      "                C = [ x for x in contexts if x[0] >= i*.10 ]\n",
      "                L = [ x for x in labels if x[0] >= i*.10 ]\n",
      "                clear_output(wait=True)\n",
      "                print 'C:{}\\t\\tAssigned:{}\\tPercentage:{}%'.format(round(max_c,2), i, round((counter*1.0/len(events))*100,2))\n",
      "                sys.stdout.flush()\n",
      "                if len(C) > 1:\n",
      "                    multi=True\n",
      "                    ranked_events[i].append( (event_name, contexts, labels, multi, ems, means) )\n",
      "                else:\n",
      "                    multi=False\n",
      "                    ranked_events[i].append( (event_name, contexts, labels, multi, ems, means) )\n",
      "                break\n",
      "#print '\\n'\n",
      "#for i in ranked_events:\n",
      "    #print 'cscore:{} to {}\\t# of Events:{}'.format(i*.10, (i+1)*.10, len(ranked_events[i]))\n",
      "\n",
      "# Create array\n",
      "#data_sr =  \n",
      "#data_mr = )\n",
      "data = { 'data_sr': np.zeros( (10, 12) ), 'data_mr': np.zeros( (10, 12) ) }\n",
      "\n",
      "## Iterate through the range of cutoff values: \n",
      "cscores = [ 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0 ]\n",
      "data_counter = 0\n",
      "for cscore in cscores:\n",
      "   \n",
      "    confusion = {'cm_sr': np.zeros( (3,3) ), 'cm_mr': np.zeros( ( 3,3) ) } # C, mC, hmC\n",
      "    cm_choice = ['C', 'mC', 'hmC' ] # Acts as index for confusion matrix update\n",
      "    # Counters\n",
      "    counters = []\n",
      "    counter_mr = 0\n",
      "    counter_sr = 0\n",
      "    cm_sr_counter = [ 0, 0, 0 ] # C, mC, hmC\n",
      "    cm_mr_counter = [ 0, 0, 0 ] # C, mC, hmC\n",
      "    \n",
      "    # Bins to hold counts\n",
      "    bins_sr = { 'f': 0, 'l': 0, 'r':0, 'b': 0, 'i': 0, 'h': 0 }\n",
      "    bins_mr = { 'f': 0, 'l': 0, 'r':0, 'b': 0, 'i': 0, 'h': 0 } # Counter for hard calls\n",
      "    soft_calls = { 'f': [], 'l': [], 'r':[], 'b': [], 'i': [], 'h': [] }    # Will hold soft calls\n",
      "    \n",
      "    ## For a given cscore, group and iterate through.\n",
      "    event_sum = 0\n",
      "    for i in xrange(9, int(cscore*10-1), -1):\n",
      "        event_sum += len(ranked_events[i])\n",
      "        for event in ranked_events[i]:\n",
      "            \n",
      "            # Unpack Variables\n",
      "            event_name = event[0]\n",
      "            contexts = event[1]\n",
      "            labels = event[2]\n",
      "            multi = event[3]\n",
      "            ems = event[4]\n",
      "            means = event[5]\n",
      "            \n",
      "            barcode = event_name.split('-')[0]\n",
      "           \n",
      "            def run_methods(bins, cm, cm_counter ):\n",
      "            \n",
      "                ## Single Read Methods\n",
      "                fchunk, fcall = Methods.first_chunk( contexts, labels, cscore )\n",
      "                lchunk, lcall = Methods.last_chunk( contexts, labels, cscore )\n",
      "                rchunk, rcall = Methods.random_chunk( contexts, labels, cscore )\n",
      "\n",
      "                ## Multi-Read Methods\n",
      "                bchunk, bcall = Methods.best_chunk( contexts, labels )\n",
      "                ichunk, icall = Methods.ind_consensus( contexts, labels, cscore )\n",
      "                hchunk, hcall = Methods.hmm_consensus( indices, ems, len(means), chunk_vector )\n",
      "\n",
      "                 # First Chunk\n",
      "                soft_calls['f'].append( fchunk )\n",
      "                if barcode == fcall[0]:\n",
      "                    bins['f'] += 1\n",
      "\n",
      "                # Last Chunk\n",
      "                soft_calls['l'].append( lchunk )\n",
      "                if barcode == lcall[0]:\n",
      "                    bins['l'] += 1\n",
      "\n",
      "                # Random Chunk\n",
      "                soft_calls['r'].append( rchunk )\n",
      "                if barcode == rcall[0]:\n",
      "                    bins['r'] += 1\n",
      "\n",
      "                # Best Chunk\n",
      "                soft_calls['b'].append( bchunk )\n",
      "                if barcode == bcall[0]:\n",
      "                    bins['b'] += 1\n",
      "\n",
      "                #HMM Consensus\n",
      "                soft_calls['h'].append( hchunk )\n",
      "                if barcode == hcall[0]:\n",
      "                    bins['h'] += 1\n",
      "                    \n",
      "                # Ind Consensus\n",
      "                soft_calls['i'].append( ichunk )\n",
      "                if barcode == icall[0]:\n",
      "                    bins['i'] += 1\n",
      "                \n",
      "                ## Confusion Matrix\n",
      "                cm_counter[ cm_choice.index( barcode) ] += 1 # Update appropriate counter\n",
      "                cm[ cm_choice.index( barcode ), cm_choice.index( icall[0] ) ] += 1 # Updates correct row given bar code\n",
      "                \n",
      "                    \n",
      "                    \n",
      "            if multi:\n",
      "                run_methods(bins_mr, confusion['cm_mr'], cm_mr_counter )\n",
      "                # update counter\n",
      "                counter_mr += 1\n",
      "            else:\n",
      "                run_methods(bins_sr, confusion['cm_sr'], cm_sr_counter)\n",
      "                counter_sr += 1\n",
      "    \n",
      "    print '# of MR events:{}\\t# of SR events:{}\\tcsore:{}'.format( counter_mr, counter_sr, cscore )\n",
      "    j = data_counter\n",
      "    for i in data:\n",
      "        if i == 'data_mr':\n",
      "            data[i][j][0] = bins_mr['f']*1.0 / counter_mr\n",
      "            data[i][j][1] = np.mean(soft_calls['f'])\n",
      "            data[i][j][2] = bins_mr['l']*1.0 / counter_mr\n",
      "            data[i][j][3] = np.mean(soft_calls['l'])\n",
      "            data[i][j][4] = bins_mr['r']*1.0 / counter_mr\n",
      "            data[i][j][5] = np.mean(soft_calls['r'])\n",
      "            data[i][j][6] = bins_mr['h']*1.0 / counter_mr\n",
      "            data[i][j][7] = np.mean(soft_calls['h'])\n",
      "            data[i][j][8] = bins_mr['b']*1.0 / counter_mr\n",
      "            data[i][j][9] = np.mean(soft_calls['b'])\n",
      "            data[i][j][10] = bins_mr['i']*1.0 / counter_mr\n",
      "            data[i][j][11] = np.mean(soft_calls['i'])\n",
      "            \n",
      "            ## CM\n",
      "            for i in xrange(3):\n",
      "                confusion['cm_mr'][i] /= cm_mr_counter[i]\n",
      "            print '-=Multi-Read Confusion Matrix=-'\n",
      "            print 'C:{}\\tmC:{}\\thmC:{}'.format( cm_mr_counter[0], cm_mr_counter[1], cm_mr_counter[2] )\n",
      "            print 'C\\tmC\\thmC\\n{}'.format( confusion['cm_mr'] )\n",
      "            \n",
      "        else:\n",
      "            data[i][j][0] = bins_sr['f']*1.0 / counter_sr\n",
      "            data[i][j][1] = np.mean(soft_calls['f'])\n",
      "            data[i][j][2] = bins_sr['l']*1.0 / counter_sr\n",
      "            data[i][j][3] = np.mean(soft_calls['l'])\n",
      "            data[i][j][4] = bins_sr['r']*1.0 / counter_sr\n",
      "            data[i][j][5] = np.mean(soft_calls['r'])\n",
      "            data[i][j][6] = bins_sr['h']*1.0 / counter_sr\n",
      "            data[i][j][7] = np.mean(soft_calls['h'])\n",
      "            data[i][j][8] = bins_sr['b']*1.0 / counter_sr\n",
      "            data[i][j][9] = np.mean(soft_calls['b'])\n",
      "            data[i][j][10] = bins_sr['i']*1.0 / counter_sr\n",
      "            data[i][j][11] = np.mean(soft_calls['i'])\n",
      "            \n",
      "            ## CM\n",
      "            for i in xrange(3):\n",
      "               confusion['cm_sr'][i] /= cm_sr_counter[i]\n",
      "            #print cm_sr_counter, '\\n', confusion['cm_sr']\n",
      "            print '-=Single-Read Confusion Matrix=-'\n",
      "            print 'C:{}\\tmC:{}\\thmC:{}'.format( cm_sr_counter[0], cm_sr_counter[1], cm_sr_counter[2] )\n",
      "            print 'C\\tmC\\thmC\\n{}'.format( confusion['cm_sr'] )\n",
      "            \n",
      "    data_counter += 1"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "accuracy_by_filter_score( data['data_sr'], 'Accuracy of Single Reads by Barcode' )\n",
      "accuracy_by_filter_score( data['data_mr'], 'Accuracy of Multi Reads by Barcode' )"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Extras:  New Improvements to Pseudo-Trained Model"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "# Acquire Events\n",
      "source = '../Data/JSON/New/'\n",
      "for root, dirnames, filenames in os.walk(source):\n",
      "    events = filenames\n",
      "\n",
      "# Read in Untrained HMM \n",
      "with open ( '../Data/HMMs/Temp_Test.txt', 'r' ) as file:\n",
      "    model = Model.read( file )\n",
      "\n",
      "# Acquire indices\n",
      "indices = { state.name: i for i, state in enumerate( model.states ) }\n",
      "\n",
      "# Rank Events by CHUNK Score\n",
      "ranked_events = {}\n",
      "for i in xrange(10):\n",
      "    ranked_events[i] = []\n",
      "\n",
      "print 'Ranking Events by CHUNK Score'\n",
      "counter = 0\n",
      "for event_name in events:  \n",
      "    counter+=1\n",
      "    # Convert JSON to event\n",
      "    event = Event.from_json( source + event_name )\n",
      "\n",
      "    # Convert event into a list of means\n",
      "    means = [seg['mean'] for seg in event.segments]\n",
      "\n",
      "    # Perform forward_backward algorithm\n",
      "    trans, ems = model.forward_backward( means )\n",
      "\n",
      "    # Partition the event into 'chunks' of context / label regions\n",
      "    contexts, labels = partition_event( indices, event, ems, means)\n",
      "\n",
      "    # Get chunk scores\n",
      "    contexts, labels = chunk_score( indices, contexts, labels, ems )\n",
      "\n",
      "    # Get chunk vector\n",
      "    contexts, labels = chunk_vector( indices, contexts, labels, ems )\n",
      "    \n",
      "    if contexts and labels:\n",
      "        max_c = max( [ x[0] for x in contexts ] ) \n",
      "        max_l = max( [ x[0] for x in labels ] )\n",
      "        \n",
      "        for i in xrange(9,-1,-1):\n",
      "            if max_c >= i*.10 and max_l >= i*.10:\n",
      "                clear_output(wait=True)\n",
      "                print 'C:{}\\t\\tAssigned:{}\\tPercentage:{}%'.format(round(max_c,2), i, round((counter*1.0/len(events))*100,2))\n",
      "                sys.stdout.flush()\n",
      "                ranked_events[i].append( (event_name, contexts, labels, ems, means) )\n",
      "                break\n",
      "print '\\n'\n",
      "for i in ranked_events:\n",
      "    print 'cscore:{} to {}\\t# of Events:{}'.format(i*.10, (i+1)*.10, len(ranked_events[i]))\n",
      "\n",
      "# Create array\n",
      "data = np.zeros( (10, 12) ) \n",
      "\n",
      "## Iterate through the range of cutoff values: \n",
      "cscores = [ 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0 ]\n",
      "data_counter = 0\n",
      "for cscore in cscores:\n",
      "    \n",
      "    #print '\\nCscore: {}\\n'.format( cscore )\n",
      "    # Counters\n",
      "    counters = []\n",
      "    counter = 0\n",
      "    \n",
      "    # Bins to hold counts\n",
      "    bins = { 'f': 0, 'l': 0, 'r':0, 'b': 0, 'i': 0, 'h': 0 }                # Counter for hard calls\n",
      "    soft_calls = { 'f': [], 'l': [], 'r':[], 'b': [], 'i': [], 'h': [] }    # Will hold soft calls\n",
      "    \n",
      "    ## For a given cscore, group and iterate through.\n",
      "    event_sum = 0\n",
      "    for i in xrange(9, int(cscore*10-1), -1):\n",
      "        event_sum += len(ranked_events[i])\n",
      "        for event in ranked_events[i]:\n",
      "            \n",
      "            # Unpack Variables\n",
      "            event_name = event[0]\n",
      "            contexts = event[1]\n",
      "            labels = event[2]\n",
      "            ems = event[3]\n",
      "            means = event[4]\n",
      "            barcode = event_name.split('-')[0]\n",
      "            # update counter\n",
      "            counter += 1\n",
      "           \n",
      "            ## Single Read Methods\n",
      "            fchunk, fcall = Methods.first_chunk( contexts, labels, cscore )\n",
      "            lchunk, lcall = Methods.last_chunk( contexts, labels, cscore )\n",
      "            rchunk, rcall = Methods.random_chunk( contexts, labels, cscore )\n",
      "            \n",
      "            ## Multi-Read Methods\n",
      "            bchunk, bcall = Methods.best_chunk( contexts, labels )\n",
      "            ichunk, icall = Methods.ind_consensus( contexts, labels, cscore )\n",
      "            hchunk, hcall = Methods.hmm_consensus( indices, ems, len(means), chunk_vector )\n",
      "\n",
      "             # First Chunk\n",
      "            soft_calls['f'].append( fchunk )\n",
      "            if barcode == fcall[0]:\n",
      "                bins['f'] += 1\n",
      "                \n",
      "            # Last Chunk\n",
      "            soft_calls['l'].append( lchunk )\n",
      "            if barcode == lcall[0]:\n",
      "                bins['l'] += 1\n",
      "                \n",
      "            # Random Chunk\n",
      "            soft_calls['r'].append( rchunk )\n",
      "            if barcode == rcall[0]:\n",
      "                bins['r'] += 1\n",
      "            \n",
      "            # Best Chunk\n",
      "            soft_calls['b'].append( bchunk )\n",
      "            if barcode == bcall[0]:\n",
      "                bins['b'] += 1\n",
      "                \n",
      "            # Ind Consensus\n",
      "            soft_calls['i'].append( ichunk )\n",
      "            if barcode == icall[0]:\n",
      "                bins['i'] += 1\n",
      "            #print 'Context_hc: {}\\tBarcode: {}\\tEvent_Name:{}'.format( icall[0], barcode, event_name )\n",
      "                \n",
      "            #HMM Consensus\n",
      "            soft_calls['h'].append( hchunk )\n",
      "            if barcode == hcall[0]:\n",
      "                bins['h'] += 1\n",
      "                \n",
      "    j = data_counter\n",
      "    data[j][0] = bins['f']*1.0 / counter\n",
      "    data[j][1] = np.mean(soft_calls['f'])\n",
      "    data[j][2] = bins['l']*1.0 / counter\n",
      "    data[j][3] = np.mean(soft_calls['l'])\n",
      "    data[j][4] = bins['r']*1.0 / counter\n",
      "    data[j][5] = np.mean(soft_calls['r'])\n",
      "    data[j][6] = bins['h']*1.0 / counter\n",
      "    data[j][7] = np.mean(soft_calls['h'])\n",
      "    data[j][8] = bins['b']*1.0 / counter\n",
      "    data[j][9] = np.mean(soft_calls['b'])\n",
      "    data[j][10] = bins['i']*1.0 / counter\n",
      "    data[j][11] = np.mean(soft_calls['i'])\n",
      "    data_counter += 1"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "accuracy_by_filter_score( data, 'Accuracy of Context Chunk by Barcode -- Pseudo_Trained HMM' )"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Plot Functions"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def accuracy_by_filter_score( data, title, sc=False ):\n",
      "    \n",
      "    # Convert Groups of arrays into lists of scores by csore.\n",
      "    first, last, random = [], [], []\n",
      "    hmm, best, ind = [], [], []\n",
      "    sample_sizes = []\n",
      "    \n",
      "    for j in xrange(0,10):\n",
      "            \n",
      "            #trial = np.loadtxt( '../Data/Results/' + trial_name, delimiter = ',' )\n",
      "            #accuracies = means[::2]\n",
      "            #acc_std = stds[::2]\n",
      "            #softcalls = means[1::2]\n",
      "            #sc_std = stds[1::2]\n",
      "            \n",
      "            trial = data[j]\n",
      "        \n",
      "            accuracies = trial[::2]\n",
      "            softcalls = trial[1::2]\n",
      "            \n",
      "            if sc:\n",
      "                f,l,r,h,b,i = softcalls\n",
      "            else:\n",
      "                f,l,r,h,b,i = accuracies\n",
      "            first.append( f ); last.append( l ); random.append( r )\n",
      "            hmm.append( h ) ; best.append( b ); ind.append( i )\n",
      "         \n",
      "            #sample_sizes.append( trial_name.split('_')[3] )\n",
      "\n",
      "    x = [ 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0 ]\n",
      "    plt.plot( x, first, label='first' )\n",
      "    plt.plot( x, last, label='last' ) \n",
      "    plt.plot( x, random, label='random' )\n",
      "    \n",
      "    plt.plot( x, hmm, label='hmm' )\n",
      "    plt.plot( x, best, label='best' )\n",
      "    plt.plot( x, ind, label='ind' )\n",
      "    \n",
      "   # plt.title( trial_name.split('_')[0] + ' - ' + trial_name.split('_')[1] \\\n",
      "    #            + ' - ' + trial_name.split('_')[2], fontsize=14 )\n",
      "    \n",
      "    #plt.title( title )\n",
      "    plt.xlabel( 'Chunk Score Cutoff', fontsize=14 )\n",
      "    plt.ylabel( 'Accuracy', fontsize=14 )\n",
      "    plt.ylim( [0.5,1.0] )\n",
      "    plt.legend(loc='lower left', bbox_to_anchor=(1.02, 0), borderaxespad=0, fontsize=14)\n",
      "    plt.gca().invert_xaxis()\n",
      "    plt.show()"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Heatmaps"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "cm_mr = np.array(\n",
      "[[ 0.83333333,  0.16666667,  0.        ],\n",
      " [ 0.22222222,  0.77777778,  0.        ],\n",
      " [ 0.,          0.,          1.        ]] )\n",
      "\n",
      "cm_sr = np.array([[ 0.81818182,  0.09090909,  0.09090909],\n",
      "[ 0.25   ,     0.75 ,       0.        ],\n",
      " [ 0.23529412,  0.   ,       0.76470588]] )\n",
      "\n",
      "'''\n",
      "plt.pcolor(cm_mr, cmap='Purples')\n",
      "plt.colorbar()\n",
      "plt.show()\n",
      "'''\n",
      "\n",
      "\n",
      "def heatmap( data, title ):\n",
      "    row_labels = ['C', 'mC', 'hmC']\n",
      "    column_labels = row_labels\n",
      "\n",
      "    fig, ax = plt.subplots()\n",
      "    heatmap = ax.pcolor(data, cmap='summer')\n",
      "\n",
      "    # put the major ticks at the middle of each cell\n",
      "    ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
      "    ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
      "\n",
      "    # want a more natural, table-like display\n",
      "    ax.invert_yaxis()\n",
      "    ax.xaxis.tick_top()\n",
      "\n",
      "\n",
      "    for y in range(data.shape[0]):\n",
      "        for x in range(data.shape[1]):\n",
      "            plt.text(x + 0.5, y + 0.5, '%.4f' % data[y, x],\n",
      "                     horizontalalignment='center',\n",
      "                     verticalalignment='center',\n",
      "                     )\n",
      "\n",
      "\n",
      "    ax.set_xticklabels(row_labels, minor=False)\n",
      "    ax.set_yticklabels(column_labels, minor=False)\n",
      "    #plt.title(title)\n",
      "    plt.ylabel( 'Label' )\n",
      "    plt.show()\n",
      "    \n",
      "heatmap( cm_mr, 'Multi-Read Heatmap\\n\\n')\n",
      "heatmap( cm_sr, 'Single-Read Heatmap\\n\\n')"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:e1d9209932393d9552f36c5b7cc486a8d070559d5b2568b37ebf6fb032321b5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}